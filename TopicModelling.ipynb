{"cells": [{"cell_type": "code", "execution_count": 1, "id": "19334d74-be3d-4d9c-ad83-118bf6ad1e69", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Warning::Spark Session already created, some configs may not take.\n"}], "source": "import sparknlp\nimport logging\nsparknlp.start()\nimport numpy as np\n\nfrom sparknlp import *\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\nfrom sparknlp.pretrained import PretrainedPipeline\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import when, col, udf\nfrom pyspark.sql.types import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import *\nfrom pyspark.ml.regression import *\nfrom pyspark.ml.classification import *\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nfrom sklearn.ensemble import VotingClassifier\nfrom pyspark.sql.types import DoubleType"}, {"cell_type": "code", "execution_count": 2, "id": "5aa9d9dc-18b2-4bbe-bbdf-6c1cfc2b9f94", "metadata": {}, "outputs": [], "source": "spark = SparkSession.builder.appName('Spark-Sentiment').getOrCreate()\nlogger = spark.sparkContext._jvm.org.apache.log4j\nlogger.LogManager.getLogger(\"org.apache.spark.scheduler\").setLevel(logger.Level.ERROR)\nlogging.getLogger(\"py4j\").setLevel(logging.ERROR)\nspark.sparkContext.setLogLevel(\"ERROR\")"}, {"cell_type": "code", "execution_count": 3, "id": "8dceb375-9c83-41a9-b1d7-9572fb81ee8e", "metadata": {}, "outputs": [], "source": "spark.conf.set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\")\nspark.conf.set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", \"path/to/your/credentials.json\")"}, {"cell_type": "code", "execution_count": 4, "id": "16701c44-5917-4f34-b7c2-f0b634a1fbd6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Read the CSV file from GCS\ndf = spark.read.format(\"csv\").option(\"header\", \"true\").\\\n                option(\"delimiter\", \"\\t\").load(\"gs://msca-bdp-student-gcs/Group4_Project_Data/amazon_reviews_us_Music_v1_00.tsv\")\ndf = df.dropna()\n\n##place to use k-means\ndf = df.withColumn(\"star_rating\",df.star_rating.cast('int'))\ndf = df.withColumn('sentiment', when(col('star_rating') <= 3, 'negative').otherwise('positive'))"}, {"cell_type": "code", "execution_count": 6, "id": "ec142afc-0122-49f4-978c-4a43898551cf", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 1:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|         review_body|\n+--------------------+\n|Love this CD alon...|\n|This is the album...|\n|  Excellent / thanks|\n|Nice variety of c...|\n|Purchased as a gi...|\n|Really enjoyed th...|\n|            Great CD|\n|       Excellent CD!|\n|                nice|\n|Outstanding music...|\n|      quite relaxing|\n|I love this CD.  ...|\n|Rhiannon Giddens ...|\n|Wrecking Ball is ...|\n|I was pleased wit...|\n|The music that in...|\n|   Excellent CD&#62;|\n|Love Or Money by ...|\n|      Just splendid!|\n|One of my favorit...|\n+--------------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df.select(\"review_body\").show()"}, {"cell_type": "code", "execution_count": 7, "id": "f28f0651-b1c1-4ec6-8f50-3fb3dee94f1b", "metadata": {}, "outputs": [], "source": "#pipeline\ntokenizer=Tokenizer(inputCol=\"review_body\", outputCol=\"review_body_words\")\nremover = StopWordsRemover(inputCol=\"review_body_words\", outputCol=\"review_body_words_filtered\")\nhashingTF = HashingTF(inputCol=\"review_body_words_filtered\", outputCol=\"hashingTF_features\")\nidf = IDF(inputCol=\"hashingTF_features\", outputCol=\"idf_features\")\nlabelIndexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"sentiment_label\")\n\npipeline = Pipeline(stages=[tokenizer,remover,hashingTF,idf,labelIndexer])"}, {"cell_type": "code", "execution_count": 6, "id": "a3cebd2a-8a1c-482e-9751-6081aaaf07c6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "preprocessed_df=pipeline.fit(df).transform(df)"}, {"cell_type": "code", "execution_count": 7, "id": "a1e2dd75-1915-46da-9934-b1f126b46ffc", "metadata": {}, "outputs": [], "source": "countVectorizer = CountVectorizer(inputCol=\"review_body_words_filtered\", outputCol=\"raw_features\")"}, {"cell_type": "code", "execution_count": 8, "id": "a3d94556-76c3-4d69-8fa8-58e2d8d0597d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "cv_model=countVectorizer.fit(preprocessed_df)"}, {"cell_type": "code", "execution_count": 9, "id": "684f6948-3ea0-4047-a981-17506dd8c835", "metadata": {}, "outputs": [], "source": "data=cv_model.transform(preprocessed_df)"}, {"cell_type": "code", "execution_count": 10, "id": "39972838-95d9-452a-976a-c31eb6afac99", "metadata": {}, "outputs": [], "source": "data=data.withColumnRenamed(\"raw_features\",\"features\")"}, {"cell_type": "code", "execution_count": null, "id": "bf0bdd94-174e-40f4-8778-fd107c28bea3", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.ml.clustering import LDA\n\nnum_topics = 10\nmax_iterations = 20\n\nlda = LDA(k=num_topics, maxIter=max_iterations,featuresCol='features')\nlda_model = lda.fit(data)\n\n"}, {"cell_type": "code", "execution_count": null, "id": "27c4cd4c-9806-44d5-b0d7-879770ea3c0f", "metadata": {}, "outputs": [], "source": "topics=lda_model.describeTopics(maxTermsPerTopic=10)"}, {"cell_type": "code", "execution_count": 13, "id": "6e21e121-59e3-480b-8462-687a963b913e", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.ml.util import MLWritable\n\nbucket_name = \"msca-bdp-student-gcs\"\nmodel_folder_path = \"Group4_Project_Data/models/LDA_model\"\n\nmodel_gcs_path = f\"gs://{bucket_name}/{model_folder_path}\"\nlda_model.write().overwrite().save(model_gcs_path)"}, {"cell_type": "code", "execution_count": null, "id": "ae1b22fa-ff2f-4b06-b421-9bdb094f122c", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "1534499d-7e24-4e92-baa7-0b993888419c", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "c39a4ec9-1eb0-47dc-b83a-840b62109526", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 13, "id": "9b2c5ecf-6444-4889-86eb-c3b72f5e8c3d", "metadata": {}, "outputs": [], "source": "#topics.show()"}, {"cell_type": "code", "execution_count": 14, "id": "68ba781e-8ec9-424f-8479-7281021473b3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Topic 0: /><br, -, album, one, like, song, songs, great, &, track\nTopic 1: , one, album, like, music, songs, great, cd, sound, first\nTopic 2: , album, great, like, music, one, best, songs, rock, hip\nTopic 3: , ok, album, like, songs, music, good, sound, new, one\nTopic 4: , album, one, like, music, cd, songs, song, -, love\nTopic 5: <br, album, like, , />, song, one, songs, good, really\nTopic 6: de, la, , que, y, en, el, es, los, un\nTopic 7: , /><br, music, one, -, recording, first, sound, also, like\nTopic 8: cd, , great, love, music, songs, one, cd., good, it.\nTopic 9: album, great, , like, cd, songs, one, best, /><br, music\n"}], "source": "for topic in topics.collect():\n    print(\"Topic {}: {}\".format(topic[0], \", \".join([cv_model.vocabulary[i] for i in topic[1]])))"}, {"cell_type": "code", "execution_count": 16, "id": "86afc049-7d6b-44e5-a1e7-a888212c323a", "metadata": {}, "outputs": [], "source": "# Read the CSV file from GCS\ndf2 = spark.read.format(\"csv\").option(\"header\", \"true\").\\\n                option(\"delimiter\", \"\\t\").load(\"gs://msca-bdp-student-gcs/Group4_Project_Data/amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv\")\ndf2 = df2.dropna()\n\n##place to use k-means\ndf2 = df2.withColumn(\"star_rating\",df2.star_rating.cast('int'))\ndf2 = df2.withColumn('sentiment', when(col('star_rating') <= 3, 'negative').otherwise('positive'))"}, {"cell_type": "code", "execution_count": 17, "id": "d0683f07-0041-48d6-9bf5-0eb4621d515d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "preprocessed_df_2=pipeline.fit(df2).transform(df2)"}, {"cell_type": "code", "execution_count": 18, "id": "42327d73-1b51-473b-bcff-0ed695833c75", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "cv_model_2=countVectorizer.fit(preprocessed_df_2)"}, {"cell_type": "code", "execution_count": 19, "id": "e6c5a4f9-df67-4b00-a01c-9eb8ae83ca9c", "metadata": {}, "outputs": [], "source": "data2=cv_model_2.transform(preprocessed_df_2)\ndata2=data2.withColumnRenamed(\"raw_features\",\"features\")"}, {"cell_type": "code", "execution_count": 20, "id": "e01f3b09-24ff-4805-87cb-8736ed2b3449", "metadata": {}, "outputs": [], "source": "predictions=lda_model.transform(data2)"}, {"cell_type": "code", "execution_count": 42, "id": "478c099e-ee47-4c26-aa02-69cc766ae299", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 89:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+-----------+--------------+----------+--------------+--------------------+--------------------+-----------+-------------+-----------+----+-----------------+---------------+--------------------+-----------+---------+--------------------+--------------------------+--------------------+--------------------+---------------+--------------------+--------------------+\n|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|    product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|review_headline|         review_body|review_date|sentiment|   review_body_words|review_body_words_filtered|  hashingTF_features|        idf_features|sentiment_label|            features|   topicDistribution|\n+-----------+-----------+--------------+----------+--------------+--------------------+--------------------+-----------+-------------+-----------+----+-----------------+---------------+--------------------+-----------+---------+--------------------+--------------------------+--------------------+--------------------+---------------+--------------------+--------------------+\n|         US|   10293599|R14LVB34Z2Z53I|B000YMOQZY|     262935067|Knockin' On Heave...|Digital_Music_Pur...|          5|            0|          0|   N|                Y|      favorites|Great  rendition....| 2015-08-31| positive|[great, , renditi...|      [great, , renditi...|(262144,[17734,22...|(262144,[17734,22...|            0.0|(262144,[0,1,3,32...|[0.01338685001653...|\n+-----------+-----------+--------------+----------+--------------+--------------------+--------------------+-----------+-------------+-----------+----+-----------------+---------------+--------------------+-----------+---------+--------------------+--------------------------+--------------------+--------------------+---------------+--------------------+--------------------+\nonly showing top 1 row\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "predictions.show(1)"}, {"cell_type": "code", "execution_count": null, "id": "8475eb1f-f1e7-4051-9ebe-1d5bf8a176ab", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 21, "id": "82d490a4-6b70-492d-a506-38a815819dec", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 82:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+\n|         review_body|   topicDistribution|\n+--------------------+--------------------+\n|Great  rendition....|[0.01320158602967...|\n+--------------------+--------------------+\nonly showing top 1 row\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# show the predicted topics for the new data\npredictions.select(\"review_body\", \"topicDistribution\").show(1)"}, {"cell_type": "code", "execution_count": 22, "id": "83c10e37-a157-42f5-b029-c34813b8a889", "metadata": {}, "outputs": [], "source": "topics=lda_model.describeTopics(maxTermsPerTopic=3)"}, {"cell_type": "code", "execution_count": 23, "id": "101b8805-3676-49d4-b785-5104e3b58f96", "metadata": {}, "outputs": [], "source": "# extract the top term indices for each topic\ntop_terms = topics.select(\"termIndices\").collect()"}, {"cell_type": "code", "execution_count": 24, "id": "b8d1a2fa-92e8-4c3c-9d26-74325bc5cd99", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ERROR:root:Exception while sending command.                                     \nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1207, in send_command\n    raise Py4JNetworkError(\"Answer from Java side is empty\")\npy4j.protocol.Py4JNetworkError: Answer from Java side is empty\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1033, in send_command\n    response = connection.send_command(command)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1211, in send_command\n    raise Py4JNetworkError(\npy4j.protocol.Py4JNetworkError: Error while receiving\nERROR:root:Exception while sending command.\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1207, in send_command\n    raise Py4JNetworkError(\"Answer from Java side is empty\")\npy4j.protocol.Py4JNetworkError: Answer from Java side is empty\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1033, in send_command\n    response = connection.send_command(command)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1211, in send_command\n    raise Py4JNetworkError(\npy4j.protocol.Py4JNetworkError: Error while receiving\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40321)\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\n"}, {"name": "stdout", "output_type": "stream", "text": "Review 0: Great  rendition. Great  song\n"}, {"name": "stderr", "output_type": "stream", "text": "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40321)\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_10627/3028070542.py\", line 7, in <module>\n    print(\"Top terms for Topic {}: {}\".format(j, [cv_model_2.vocabulary[int(row.topicDistribution.argmax())]]))\n  File \"/usr/lib/spark/python/pyspark/ml/feature.py\", line 919, in vocabulary\n    return self._call_java(\"vocabulary\")\n  File \"/usr/lib/spark/python/pyspark/ml/wrapper.py\", line 54, in _call_java\n    return _java2py(sc, m(*java_args))\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1303, in __call__\n    answer = self.gateway_client.send_command(command)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1031, in send_command\n    connection = self._get_connection()\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 979, in _get_connection\n    connection = self._create_connection()\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 985, in _create_connection\n    connection.start()\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1127, in start\n    raise Py4JNetworkError(msg, e)\npy4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:40321)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n    connection = self.deque.pop()\nIndexError: pop from an empty deque\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n    self.socket.connect((self.address, self.port))\nConnectionRefusedError: [Errno 111] Connection refused\n"}, {"ename": "Py4JNetworkError", "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:40321)", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:977\u001b[0m, in \u001b[0;36mGatewayClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeque\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n", "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque", "\nDuring handling of the above exception, another exception occurred:\n", "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1115\u001b[0m, in \u001b[0;36mGatewayConnection.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n", "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused", "\nDuring handling of the above exception, another exception occurred:\n", "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)", "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i, row\u001b[38;5;241m.\u001b[39mreview_body))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(top_terms)):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop terms for Topic \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(j, [\u001b[43mcv_model_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocabulary\u001b[49m[\u001b[38;5;28mint\u001b[39m(row\u001b[38;5;241m.\u001b[39mtopicDistribution\u001b[38;5;241m.\u001b[39margmax())]]))\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/feature.py:919\u001b[0m, in \u001b[0;36mCountVectorizerModel.vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;129m@since\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.6.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocabulary\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    916\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    An array of terms in the vocabulary.\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_java\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvocabulary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py:54\u001b[0m, in \u001b[0;36mJavaWrapper._call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     52\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[1;32m     53\u001b[0m java_args \u001b[38;5;241m=\u001b[39m [_py2java(sc, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _java2py(sc, \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjava_args\u001b[49m\u001b[43m)\u001b[49m)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1031\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1031\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:979\u001b[0m, in \u001b[0;36mGatewayClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeque\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m--> 979\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:985\u001b[0m, in \u001b[0;36mGatewayClient._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    983\u001b[0m     connection \u001b[38;5;241m=\u001b[39m GatewayConnection(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property)\n\u001b[0;32m--> 985\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1127\u001b[0m, in \u001b[0;36mGatewayConnection.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while trying to connect to the Java \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m   1126\u001b[0m logger\u001b[38;5;241m.\u001b[39mexception(msg)\n\u001b[0;32m-> 1127\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(msg, e)\n", "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:40321)"]}], "source": "\n\n# show the top terms for each predicted topic\nfor i, row in enumerate(predictions.select(\"review_body\", \"topicDistribution\").collect()):\n    if i>=10:\n        break\n    print(\"Review {}: {}\".format(i, row.review_body))\n    for j in range(len(top_terms)):\n        print(\"Top terms for Topic {}: {}\".format(j, [cv_model_2.vocabulary[int(row.topicDistribution.argmax())]]))\n\n"}, {"cell_type": "code", "execution_count": null, "id": "d43d22e9-0615-4d7a-ab84-7f1dc9d52326", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "a768dc1a-2035-4f44-a290-aa5d5b7754e6", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}